<!DOCTYPE html>
<html lang="fr"><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>Minzhao Zhu</title>

<!--[if lt IE 9]>
<script src="//html5shim.googlecode.com/svn/trunk/html5.js"></script>
<![endif]-->

<!-- Fichiers CSS -->
<link rel="stylesheet" href="files/reset.css">
<!--[if lt IE 9]> 
	<link rel="stylesheet" href="css/cv.css" media="screen">
<![endif]-->
<link rel="stylesheet" media="screen and (max-width:480px)" href="files/mobile.css">
<link rel="stylesheet" media="screen and (min-width:481px)" href="files/cv.css">
<link rel="stylesheet" media="print" href="files/print.css">
<style>        
    .sep {
    }
    .sep td {
        padding-bottom:30px;
    }
</style>
</head>

<body>

	<!-- Header -->
	<header role="banner">
		<div class="container_16">
				<hgroup>
					<h1>Minzhao Zhu</h1>
					<ul>
					<li><b>Research Engineer, Bytedance AI Lab</b></li>
					<li>Haidian North Second Street, Zhongguancun, Haidian District, Beijing, China</li>
					<li>Email: <a href="mailto:minzhaozhu@gmail.com">minzhaozhu[at]gmail.com</a></li>
					<li><a href="figures/MinzhaoZhu_BIT.pdf">CV</a> </li>
				
				</ul>
				</hgroup>

				<figure>
					<img src="files/temp.jpg" alt="minzhao">
				</figure>
		</div>
	</header>
	
	
	<!-- Main -->
	<section role="main" class="container_16 clearfix">
		<div class="grid_16">			
				<h3>About Me</h3>

			    <p>I am an research engineer at Bytedance AI Lab. Before that, I received my M.S degree in Control Science and Engineering at <a href="https://english.bit.edu.cn/">Beijing Institute of Technology</a>. </p>
				<p> My research interests are localization, perception and visual navigation. </p>

		</div>
		
		<div class="grid_16">			
				<h3>News</h3>

				<li>Jul. 2022, Our paper got accepted to IROS 2022.

				<li>Jul. 2020, I join Bytedance as a Research Engineer.

				<li>Jun. 2020, I received my M.S degree at Beijing Institute of Technology.
		</div>

		

		<div class="grid_16">			
				<h3>Publications</h3>				
				<table border-spacing="100 50px">
					<col width=45%>
					<col width=55%>

					<tr class="sep">
						<td>
<!--							<img src="figures/iros22.png" class="icon">-->
							<video controls width="400" poster="figures/iros22.png">
								<source src="figures/iros22.mp4"
										type="video/mp4">
							</video>
						</td>
						<td class="tabletext">
							<p><b>Minzhao Zhu</b>, Binglei Zhao, Tao Kong</a><br>
								<b><i>Navigating to Objects in Unseen Environments by Distance Prediction<br>
									IROS 2022 </i></b><br>
									<a href="https://arxiv.org/pdf/2202.03735.pdf">[pdf]</a><br>
							<p	style = "text-align:justify" >
							We propose a Object Goal Navigation (ObjectNav) method based on a estimated distance map.
									A neural network takes an explored semantic map as input, and estimates the distance from map cells to the target object based on learned spatial relations between objects. With such distance map, the agent explores
									and searches for the target using either classical planning methods or learned policy.
							Our	method outperforms the RL-based baseline with only 12% training data.
							</p>
						</td>
					</tr>

					<tr class="sep"> 
						<td>
							<video controls width="400" poster="figures/RAS.png">
								<source src="figures/paper.mp4"
										type="video/mp4">

							</video>

						</td> 
						<td class="tabletext">
							<p>Mengyin Fu, <b>Minzhao Zhu</b>, Yi Yang, Wenjie Song, Meiling Wang <br>
							<b><i>LiDAR-based vehicle localization on the satellite image via a neural network <br>
								Robotics and Autonomous Systems, 2020 </i></b><br>
							<a href="https://minzhao1995.github.io/figures/RAS.pdf">[pdf]</a><br>
							<p	style = "text-align:justify" > 	We propose a vehicle localization method using satellite images in GNSS-denied areas.
								A neural network compares the spatial-discriminative feature maps of LiDAR grid-map and
								satellite image patches. It outputs the probabilities of correspondence, based on which a particle
								filter estimates the probability distribution of the vehicle's pose.</p>
						</td> 
					</tr>


				 </table> 


		</div>
		<div class="grid_16">
			<h3>Projects</h3>
			<table border-spacing="100 60px">
				<col width=45%>
				<col width=55%>


				<tr class="sep">
					<td>

						<video controls width="400" poster="figures/ccdc.png">
							<source src="figures/ccdc.mp4"
									type="video/mp4">
						</video>
					</td>
					<td class="tabletext">
						<p><b>Air-Ground Cross-View based LiDAR Odometry and Mapping</b><br>
						<p	style = "text-align:justify" >  	To reduce the drifting error of the LiDAR odometry, the satellite image patch, which is cropped on the pose given by the odometry, is compared with the LiDAR grid-map via a neural network. The network directly outputs the pose correction offset, which is added to the factor graph.</p>
					</td>
				</tr>

				<tr class="sep">
					<td>
						<img src="figures/fusion.png" class="icon">
					</td>
					<td class="tabletext">
						<p> <b>Air-ground Cross-view Semantic SLAM  </b><br>
						<p	style = "text-align:justify" > 	To improve the precision of semantic segmentation, based on a spherical projection image, the semantic information from aerial view is fused with multiple ground views via Bayesian update.</p>
					</td>
				</tr>

				<tr class="sep">
					<td>
						<img src="figures/air_ground.png" class="icon">
					</td>
					<td class="tabletext">
						<p> <b>UAV-UGV Cooperative System  </b><br>
						<p	style = "text-align:justify" > The UAV and UGV search and track the moving target (a vehicle) in an unknown area (3 km x 3 km) collaboratively. I led our team to build this system and we won the <b>first place </b> in the 2018 China Unmanned System Challenge (Air-Ground Collaboration Contest).</p>
					</td>
				</tr>


				<tr class="sep">
					<td>
						<img src="figures/hongqi.jpg" class="icon">
					</td>
					<td class="tabletext">
						<p> <b>Hongqi-H7 Self-driving Car  </b><br>
						<p	style = "text-align:justify" > 	We won the <b> first place </b> in the 2017 China Smart Car Future Challenge Highway Contest.</p>
					</td>
				</tr>

				<tr class="sep">
					<td>
						<img src="https://minzhao1995.github.io/figures/kvm.gif" class="icon">
					</td>
					<td class="tabletext">
						<p> <b> Intelligent Mouse and Keyboard Switcher </b><br>
						<p	style = "text-align:justify" > 	This project is designed to make it easy for users to operate multiple computers with a single mouse and keyboard. A face orientation recognition algorithm is designed to find which computer the user desires to use. Then the device automatically switches the mouse & keyboard signals to that computer.</p>
					</td>
				</tr>

				<tr class="sep">
					<td>
						<img src="https://minzhao1995.github.io/figures/mapping.gif" class="icon">
					</td>
					<td class="tabletext">
						<p> <b> BankBot </b><br>
						<p	style = "text-align:justify" > 	This mobile robot is designed for bank reception service. Up until now, the robot has been deployed into service at 35 banks for 4 years.</p>
					</td>
				</tr>

			</table>


		</div>
		<div class="grid_16">
			<table border=0 cellpadding=0 width=100% style="line-height:18pt;  border-spacing: 0 6px;"> 
					
					<tr> 
						<td>
							<a href="#top">Back to top</a>
						</td> 
						<td style="text-align:right;vertical-align:top;padding:0"> 
							Last updated: Sep 2022
						 </td> 
					</tr> 			
				 </table> 			
		</div>
		
	</section>

<!-- Scripts JavaScript -->
<script src="files/jquery-1.js"></script>
<script src="files/validate.js"></script>
<script files/plugins.js"></script>

</body></html>
